# Veclon Copilot

Local AI assistant for result interpretation and report drafting.

Planned local runtime: Ollama or llama.cpp (Metal on macOS).
